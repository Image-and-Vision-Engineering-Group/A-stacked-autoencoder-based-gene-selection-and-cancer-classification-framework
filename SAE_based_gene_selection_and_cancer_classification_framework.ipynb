{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "AWuu6v7KAMH0"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Activation, AveragePooling2D\n",
        "from keras import regularizers\n",
        "from keras.optimizers import Adam\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "kernel = 1.0 * RBF(1.0)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "from sklearn import preprocessing\n"
      ],
      "metadata": {
        "id": "9o-f3y1PVnu7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "data = arff.loadarff('/content/drive/MyDrive/final_paper/MLL.arff') # selcet labeled data according to application\n",
        "df = pd.DataFrame(data[0])\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVg8osf2Vohw",
        "outputId": "b9663379-076f-4623-f676-543c3f88c06e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72, 12583)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "print( df.iloc[:,-1].unique()) # to check number of classes in the dataset\n",
        "# label_encoder object knows how to understand word labels.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'species'.\n",
        "df.iloc[:,-1]= label_encoder.fit_transform(df.iloc[:,-1])\n",
        "df.iloc[:,-1].unique()"
      ],
      "metadata": {
        "id": "2yfKhKJ0CGwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced0190c-94d9-4c74-fc0e-cb5d94eacd7f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'ALL' b'MLL' b'AML']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate dataset according to classes\n",
        "x1 = df[df.iloc[:,-1] == 0]\n",
        "x2 = df[df.iloc[:,-1] == 1]\n",
        "x3 = df[df.iloc[:,-1] == 2]\n",
        "print(x1.shape,x2.shape,x3.shape) # to check number of samples in each class"
      ],
      "metadata": {
        "id": "XRnZSKiQEU59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab1654d-096a-49c3-9355-4c33e7026c78"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 12583) (28, 12583) (20, 12583)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separate the target classes\n",
        "Y1 = x1.iloc[:,-1]\n",
        "Y2 = x2.iloc[:,-1]\n",
        "Y3 = x3.iloc[:,-1]\n",
        "# remove the class label\n",
        "del x1[x1.columns[-1]]\n",
        "del x2[x2.columns[-1]]\n",
        "del x3[x3.columns[-1]]\n",
        "print(x1.shape,x2.shape,x3.shape) # to check number of samples in each class without class labels"
      ],
      "metadata": {
        "id": "ztzO11njJm1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6d632c-1c08-46aa-cd7a-c3f0b84146c3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 12582) (28, 12582) (20, 12582)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select samples for augmentation\n",
        "n=10\n",
        "df1=x1.sample(n =10)\n",
        "df2=x2.sample(n = 10)\n",
        "df3=x3.sample(n = 10)\n"
      ],
      "metadata": {
        "id": "kyW3VEE2EYAd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mu, sigma = 0, 0.1\n",
        "# creating a noise with the same dimension as the dataset\n",
        "noise1 = np.random.normal(mu, sigma, [10,x1.shape[1]])\n",
        "noise2 = np.random.normal(mu, sigma, [10,x1.shape[1]])\n",
        "noise3 = np.random.normal(mu, sigma, [10,x1.shape[1]])\n",
        "print(noise1.shape,noise2.shape,noise3.shape) # check the shape of the noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ukk92IGEm8s",
        "outputId": "d8591722-f642-4f2d-d9a5-e3fa41648e2b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 12582) (10, 12582) (10, 12582)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add noise to selected samples\n",
        "noise_factor = 0.1\n",
        "DF1 =  df1+ (noise_factor*noise1)\n",
        "DF2=   df2+ (noise_factor*noise2)\n",
        "DF3=   df3+ (noise_factor*noise3)\n"
      ],
      "metadata": {
        "id": "2aD2dADTGHKf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add noisy sample to original data\n",
        "verti_df1= pd.concat([x1, DF1], axis=0)\n",
        "verti_df2= pd.concat([x2, DF2], axis=0)\n",
        "verti_df3= pd.concat([x3, DF3], axis=0)\n",
        "print(verti_df1.shape,verti_df2.shape,verti_df3.shape)# check the shape of the augmented data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diRFP5NeGZCh",
        "outputId": "e1e44bb8-fa58-4802-de93-40f795f6f5b7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 12582) (38, 12582) (30, 12582)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge all samples to new augmented data\n",
        "new_data=pd.concat([verti_df1,verti_df2,verti_df3],axis=0)\n",
        "new_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxQrOCULHLyz",
        "outputId": "98df3497-414c-4aa2-f970-9094742fbb26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 12582)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create equal class labels\n",
        "y1= Y1.sample(n = 10)\n",
        "y2= Y2.sample(n = 10)\n",
        "y3= Y3.sample(n = 10)\n",
        "\n",
        "new_y1= pd.concat([Y1,y1],axis=0)\n",
        "new_y2=pd.concat([Y2,y2],axis=0)\n",
        "new_y3=pd.concat([Y3,y3],axis=0)\n",
        "new_Class= pd.concat([new_y1,new_y2,new_y3],axis=0)\n",
        "new_Class.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAb5kIqOHzQ6",
        "outputId": "c6e5cfaa-4159-4b8f-fc34-626e661dfd78"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102,)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge class label to dataset to create augmented dataset(data with label)\n",
        "from sklearn.utils import shuffle\n",
        "NEW_dataset=new_data.reset_index(drop=True).merge(new_Class.reset_index(drop=True), left_index=True, right_index=True)\n",
        "NEW_dataset= (shuffle(NEW_dataset)).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Xedu8mtFI9vr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(NEW_dataset.shape)\n",
        "dataset= NEW_dataset.values\n",
        "X = dataset[:,:-1]\n",
        "Y = dataset[:,-1]\n",
        "print(X.shape,Y.shape)\n",
        "input_dim=X.shape[1]\n",
        "print(input_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDFYvBUZKqFu",
        "outputId": "e8346561-280f-4ba5-fd25-d0406a5c6fd2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102, 12583)\n",
            "(102, 12582) (102,)\n",
            "12582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scl_train = scaler.fit_transform(X_train)\n",
        "X_scl_test = scaler.fit_transform(X_test)\n",
        "X_scl = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Qx3LJFQNKqIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = keras.Input(shape=(input_dim,))\n",
        "encoded = layers.Dense(1024, activation='relu')(input_data)\n",
        "output = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
        "en_m=keras.Model(input_data,encoded)\n",
        "#encoder_m.summary()\n",
        "auto_m = keras.Model(input_data, output)\n",
        "auto_m.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujbaF9IRKqMU",
        "outputId": "7f3035f2-d9bf-4493-c23d-63e815e8bd78"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12582)]           0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              12884992  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 12582)             12896550  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25781542 (98.35 MB)\n",
            "Trainable params: 25781542 (98.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_m.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "auto_m.fit(X_scl_train, X_scl_train,\n",
        "                epochs=100,\n",
        "                batch_size=30,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_scl_test, X_scl_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzXPnml0MEcV",
        "outputId": "fd9222d5-0d05-4fc9-c180-0798a466ec7e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 842ms/step - loss: 0.6826 - val_loss: 0.6820\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 2s 819ms/step - loss: 0.6349 - val_loss: 0.6698\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 2s 813ms/step - loss: 0.6228 - val_loss: 0.6707\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 752ms/step - loss: 0.6169 - val_loss: 0.6594\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.6084 - val_loss: 0.6474\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 761ms/step - loss: 0.6027 - val_loss: 0.6393\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 2s 691ms/step - loss: 0.6001 - val_loss: 0.6386\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 2s 583ms/step - loss: 0.5965 - val_loss: 0.6381\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 2s 778ms/step - loss: 0.5931 - val_loss: 0.6406\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 775ms/step - loss: 0.5907 - val_loss: 0.6394\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.5884 - val_loss: 0.6373\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 502ms/step - loss: 0.5857 - val_loss: 0.6336\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.5830 - val_loss: 0.6317\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 495ms/step - loss: 0.5806 - val_loss: 0.6286\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 516ms/step - loss: 0.5781 - val_loss: 0.6250\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.5761 - val_loss: 0.6248\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 496ms/step - loss: 0.5738 - val_loss: 0.6240\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 692ms/step - loss: 0.5720 - val_loss: 0.6235\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 774ms/step - loss: 0.5699 - val_loss: 0.6228\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 823ms/step - loss: 0.5682 - val_loss: 0.6204\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.5667 - val_loss: 0.6190\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 475ms/step - loss: 0.5650 - val_loss: 0.6182\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 483ms/step - loss: 0.5635 - val_loss: 0.6153\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 494ms/step - loss: 0.5619 - val_loss: 0.6141\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.5606 - val_loss: 0.6148\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 516ms/step - loss: 0.5593 - val_loss: 0.6149\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 594ms/step - loss: 0.5579 - val_loss: 0.6135\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 790ms/step - loss: 0.5566 - val_loss: 0.6121\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 842ms/step - loss: 0.5552 - val_loss: 0.6098\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 2s 504ms/step - loss: 0.5541 - val_loss: 0.6102\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5527 - val_loss: 0.6096\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 2s 504ms/step - loss: 0.5515 - val_loss: 0.6071\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 532ms/step - loss: 0.5504 - val_loss: 0.6068\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.5493 - val_loss: 0.6058\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5483 - val_loss: 0.6050\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 561ms/step - loss: 0.5472 - val_loss: 0.6036\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 775ms/step - loss: 0.5462 - val_loss: 0.6031\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 776ms/step - loss: 0.5453 - val_loss: 0.6029\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 2s 491ms/step - loss: 0.5444 - val_loss: 0.6019\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 0.5436 - val_loss: 0.6010\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 1s 505ms/step - loss: 0.5428 - val_loss: 0.6004\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 510ms/step - loss: 0.5420 - val_loss: 0.5996\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 1s 506ms/step - loss: 0.5413 - val_loss: 0.5988\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 1s 506ms/step - loss: 0.5405 - val_loss: 0.5987\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 561ms/step - loss: 0.5398 - val_loss: 0.5976\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 809ms/step - loss: 0.5391 - val_loss: 0.5969\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 3s 861ms/step - loss: 0.5385 - val_loss: 0.5974\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 2s 530ms/step - loss: 0.5378 - val_loss: 0.5957\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5372 - val_loss: 0.5950\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 516ms/step - loss: 0.5367 - val_loss: 0.5948\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 544ms/step - loss: 0.5361 - val_loss: 0.5936\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 2s 532ms/step - loss: 0.5356 - val_loss: 0.5937\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.5351 - val_loss: 0.5934\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 2s 725ms/step - loss: 0.5346 - val_loss: 0.5931\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 766ms/step - loss: 0.5341 - val_loss: 0.5922\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 688ms/step - loss: 0.5337 - val_loss: 0.5918\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.5333 - val_loss: 0.5909\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 2s 563ms/step - loss: 0.5328 - val_loss: 0.5909\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.5324 - val_loss: 0.5902\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 582ms/step - loss: 0.5320 - val_loss: 0.5903\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 2s 536ms/step - loss: 0.5317 - val_loss: 0.5896\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 505ms/step - loss: 0.5313 - val_loss: 0.5894\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 830ms/step - loss: 0.5310 - val_loss: 0.5890\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 3s 976ms/step - loss: 0.5306 - val_loss: 0.5888\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 3s 933ms/step - loss: 0.5303 - val_loss: 0.5888\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 3s 850ms/step - loss: 0.5301 - val_loss: 0.5883\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.5298 - val_loss: 0.5880\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 486ms/step - loss: 0.5296 - val_loss: 0.5871\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 1s 488ms/step - loss: 0.5294 - val_loss: 0.5866\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 1s 497ms/step - loss: 0.5291 - val_loss: 0.5870\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 1s 491ms/step - loss: 0.5289 - val_loss: 0.5865\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 0.5287 - val_loss: 0.5876\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 843ms/step - loss: 0.5285 - val_loss: 0.5862\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 786ms/step - loss: 0.5283 - val_loss: 0.5869\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 1s 487ms/step - loss: 0.5280 - val_loss: 0.5858\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 489ms/step - loss: 0.5279 - val_loss: 0.5863\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5277 - val_loss: 0.5855\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.5275 - val_loss: 0.5857\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5274 - val_loss: 0.5853\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.5273 - val_loss: 0.5855\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.5271 - val_loss: 0.5852\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 820ms/step - loss: 0.5270 - val_loss: 0.5849\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 865ms/step - loss: 0.5269 - val_loss: 0.5848\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.5268 - val_loss: 0.5849\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 0.5266 - val_loss: 0.5839\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 1s 487ms/step - loss: 0.5265 - val_loss: 0.5849\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 1s 490ms/step - loss: 0.5264 - val_loss: 0.5833\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5263 - val_loss: 0.5852\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5262 - val_loss: 0.5839\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 599ms/step - loss: 0.5261 - val_loss: 0.5838\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 806ms/step - loss: 0.5260 - val_loss: 0.5834\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 819ms/step - loss: 0.5259 - val_loss: 0.5839\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 494ms/step - loss: 0.5259 - val_loss: 0.5831\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 1s 505ms/step - loss: 0.5259 - val_loss: 0.5839\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.5258 - val_loss: 0.5832\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 1s 510ms/step - loss: 0.5257 - val_loss: 0.5836\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.5256 - val_loss: 0.5832\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 502ms/step - loss: 0.5255 - val_loss: 0.5840\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 547ms/step - loss: 0.5254 - val_loss: 0.5834\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 796ms/step - loss: 0.5254 - val_loss: 0.5837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c8d1faf2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding two new layers autoencoder 2\n",
        "en2=(Dense(512,activation='relu'))(auto_m.layers[-2].output)\n",
        "de2=(Dense(1024,activation='relu'))(en2)\n",
        "ou=(Dense(input_dim,activation='sigmoid'))(de2)\n",
        "#creating new model\n",
        "ae_model=keras.Model(inputs=auto_m.input, outputs=[ou])\n",
        "encoder_model=keras.Model(inputs=auto_m.input, outputs=[en2])\n",
        "encoder_model.summary()\n",
        "ae_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhsA2-_L-li",
        "outputId": "628f7cbe-cefb-4b54-9f0f-323f4fec8e1a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12582)]           0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              12884992  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13409792 (51.15 MB)\n",
            "Trainable params: 13409792 (51.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12582)]           0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              12884992  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 12582)             12896550  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26831654 (102.35 MB)\n",
            "Trainable params: 26831654 (102.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train new model\n",
        "ae_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "ae_model.fit(X_scl_train, X_scl_train,\n",
        "                epochs=100,\n",
        "                batch_size=30,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_scl_test, X_scl_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-LIQcR9NJd1",
        "outputId": "e072e9b9-4d6d-4d56-eb33-090cdf402328"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 575ms/step - loss: 0.6829 - val_loss: 0.6756\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 509ms/step - loss: 0.6338 - val_loss: 0.6583\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 505ms/step - loss: 0.6190 - val_loss: 0.6617\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 508ms/step - loss: 0.6070 - val_loss: 0.6459\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5945 - val_loss: 0.6394\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.5865 - val_loss: 0.6346\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 2s 661ms/step - loss: 0.5804 - val_loss: 0.6311\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 2s 791ms/step - loss: 0.5746 - val_loss: 0.6260\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 2s 759ms/step - loss: 0.5698 - val_loss: 0.6243\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 503ms/step - loss: 0.5653 - val_loss: 0.6203\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5614 - val_loss: 0.6175\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 539ms/step - loss: 0.5574 - val_loss: 0.6134\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 540ms/step - loss: 0.5538 - val_loss: 0.6116\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5505 - val_loss: 0.6083\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5475 - val_loss: 0.6047\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 772ms/step - loss: 0.5447 - val_loss: 0.6032\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 2s 827ms/step - loss: 0.5422 - val_loss: 0.5996\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 752ms/step - loss: 0.5399 - val_loss: 0.5982\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5380 - val_loss: 0.5963\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 502ms/step - loss: 0.5362 - val_loss: 0.5940\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 519ms/step - loss: 0.5348 - val_loss: 0.5930\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 2s 556ms/step - loss: 0.5334 - val_loss: 0.5912\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 571ms/step - loss: 0.5322 - val_loss: 0.5906\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 2s 793ms/step - loss: 0.5312 - val_loss: 0.5881\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 3s 965ms/step - loss: 0.5303 - val_loss: 0.5885\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 3s 957ms/step - loss: 0.5296 - val_loss: 0.5874\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 3s 872ms/step - loss: 0.5290 - val_loss: 0.5861\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 517ms/step - loss: 0.5283 - val_loss: 0.5865\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.5279 - val_loss: 0.5853\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 506ms/step - loss: 0.5274 - val_loss: 0.5853\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5270 - val_loss: 0.5848\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.5266 - val_loss: 0.5851\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 489ms/step - loss: 0.5263 - val_loss: 0.5842\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 719ms/step - loss: 0.5261 - val_loss: 0.5842\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 3s 881ms/step - loss: 0.5258 - val_loss: 0.5842\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 772ms/step - loss: 0.5256 - val_loss: 0.5850\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5255 - val_loss: 0.5836\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.5253 - val_loss: 0.5842\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 515ms/step - loss: 0.5252 - val_loss: 0.5838\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.5250 - val_loss: 0.5848\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 547ms/step - loss: 0.5250 - val_loss: 0.5834\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 545ms/step - loss: 0.5249 - val_loss: 0.5851\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 823ms/step - loss: 0.5248 - val_loss: 0.5834\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 2s 775ms/step - loss: 0.5247 - val_loss: 0.5848\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.5248 - val_loss: 0.5839\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 529ms/step - loss: 0.5247 - val_loss: 0.5857\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.5247 - val_loss: 0.5844\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.5247 - val_loss: 0.5848\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 551ms/step - loss: 0.5247 - val_loss: 0.5852\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 1s 493ms/step - loss: 0.5247 - val_loss: 0.5847\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 589ms/step - loss: 0.5246 - val_loss: 0.5842\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 2s 817ms/step - loss: 0.5246 - val_loss: 0.5846\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 3s 893ms/step - loss: 0.5246 - val_loss: 0.5861\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 2s 522ms/step - loss: 0.5246 - val_loss: 0.5838\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 547ms/step - loss: 0.5246 - val_loss: 0.5855\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.5246 - val_loss: 0.5857\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 535ms/step - loss: 0.5246 - val_loss: 0.5849\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 2s 529ms/step - loss: 0.5246 - val_loss: 0.5857\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5246 - val_loss: 0.5850\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 688ms/step - loss: 0.5247 - val_loss: 0.5852\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 2s 829ms/step - loss: 0.5246 - val_loss: 0.5854\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 850ms/step - loss: 0.5247 - val_loss: 0.5853\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 517ms/step - loss: 0.5248 - val_loss: 0.5844\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.5248 - val_loss: 0.5857\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 1s 495ms/step - loss: 0.5247 - val_loss: 0.5839\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5246 - val_loss: 0.5859\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 511ms/step - loss: 0.5246 - val_loss: 0.5843\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.5247 - val_loss: 0.5854\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 2s 690ms/step - loss: 0.5246 - val_loss: 0.5844\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 794ms/step - loss: 0.5245 - val_loss: 0.5848\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 2s 870ms/step - loss: 0.5244 - val_loss: 0.5845\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 2s 530ms/step - loss: 0.5245 - val_loss: 0.5844\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 515ms/step - loss: 0.5244 - val_loss: 0.5851\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.5244 - val_loss: 0.5841\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 542ms/step - loss: 0.5244 - val_loss: 0.5854\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 504ms/step - loss: 0.5244 - val_loss: 0.5841\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.5244 - val_loss: 0.5852\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 680ms/step - loss: 0.5244 - val_loss: 0.5847\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 3s 887ms/step - loss: 0.5243 - val_loss: 0.5848\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 2s 849ms/step - loss: 0.5244 - val_loss: 0.5855\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 0.5244 - val_loss: 0.5854\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.5243 - val_loss: 0.5840\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.5244 - val_loss: 0.5867\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.5244 - val_loss: 0.5840\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 1s 508ms/step - loss: 0.5244 - val_loss: 0.5860\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 2s 552ms/step - loss: 0.5244 - val_loss: 0.5855\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 2s 770ms/step - loss: 0.5245 - val_loss: 0.5851\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 3s 853ms/step - loss: 0.5244 - val_loss: 0.5852\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 783ms/step - loss: 0.5244 - val_loss: 0.5860\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 519ms/step - loss: 0.5244 - val_loss: 0.5849\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.5243 - val_loss: 0.5856\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.5243 - val_loss: 0.5850\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.5244 - val_loss: 0.5858\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 0.5243 - val_loss: 0.5851\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 532ms/step - loss: 0.5244 - val_loss: 0.5854\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 782ms/step - loss: 0.5243 - val_loss: 0.5859\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 840ms/step - loss: 0.5244 - val_loss: 0.5856\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 2s 799ms/step - loss: 0.5244 - val_loss: 0.5849\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 539ms/step - loss: 0.5244 - val_loss: 0.5863\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 1s 494ms/step - loss: 0.5243 - val_loss: 0.5842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c8d81d3610>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding two new layers\n",
        "en3=(Dense(100,activation='relu'))(ae_model.layers[-3].output)\n",
        "de3=(Dense(512,activation='relu'))(en3)\n",
        "de3=(Dense(1024,activation='relu'))(de3)\n",
        "ou3=(Dense(input_dim,activation='sigmoid'))(de3)"
      ],
      "metadata": {
        "id": "59ylJG7rNBdW"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating final stacked model\n",
        "ae_model_new=keras.Model(inputs=auto_m.input, outputs=[ou3])\n",
        "SAE=keras.Model(inputs=auto_m.input, outputs=[ae_model_new.layers[-4].output])\n",
        "ae_model_new.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPlll-C4NBg5",
        "outputId": "b794bd15-eb47-41f1-c811-fecdc31e1adb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12582)]           0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              12884992  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               51300     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               51712     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 12582)             12896550  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26934666 (102.75 MB)\n",
            "Trainable params: 26934666 (102.75 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train final stacked model\n",
        "ae_model_new.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "ae_model_new.fit(X_scl_train, X_scl_train,\n",
        "                epochs=100,\n",
        "                batch_size=30,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_scl_test, X_scl_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCbgQ6EJNsTw",
        "outputId": "30d623c4-533d-40ba-cbc9-ec28a1e54aa8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 594ms/step - loss: 0.6851 - val_loss: 0.6680\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 2s 515ms/step - loss: 0.6484 - val_loss: 0.6625\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 499ms/step - loss: 0.6283 - val_loss: 0.6653\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 3s 871ms/step - loss: 0.6214 - val_loss: 0.6638\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 814ms/step - loss: 0.6077 - val_loss: 0.6468\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.5995 - val_loss: 0.6413\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 493ms/step - loss: 0.5935 - val_loss: 0.6380\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 506ms/step - loss: 0.5878 - val_loss: 0.6334\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 498ms/step - loss: 0.5821 - val_loss: 0.6305\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.5771 - val_loss: 0.6279\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 543ms/step - loss: 0.5729 - val_loss: 0.6247\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 555ms/step - loss: 0.5692 - val_loss: 0.6212\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 838ms/step - loss: 0.5659 - val_loss: 0.6202\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 2s 822ms/step - loss: 0.5626 - val_loss: 0.6175\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.5595 - val_loss: 0.6150\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 513ms/step - loss: 0.5566 - val_loss: 0.6128\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 2s 562ms/step - loss: 0.5537 - val_loss: 0.6112\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 516ms/step - loss: 0.5510 - val_loss: 0.6082\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.5487 - val_loss: 0.6072\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 505ms/step - loss: 0.5465 - val_loss: 0.6033\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 2s 659ms/step - loss: 0.5442 - val_loss: 0.6014\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 2s 816ms/step - loss: 0.5422 - val_loss: 0.6008\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 809ms/step - loss: 0.5405 - val_loss: 0.5977\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 2s 537ms/step - loss: 0.5388 - val_loss: 0.5965\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 508ms/step - loss: 0.5372 - val_loss: 0.5950\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.5359 - val_loss: 0.5935\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 837ms/step - loss: 0.5347 - val_loss: 0.5940\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 781ms/step - loss: 0.5336 - val_loss: 0.5911\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 851ms/step - loss: 0.5328 - val_loss: 0.5903\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 2s 821ms/step - loss: 0.5317 - val_loss: 0.5906\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 2s 602ms/step - loss: 0.5310 - val_loss: 0.5896\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 506ms/step - loss: 0.5302 - val_loss: 0.5895\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.5295 - val_loss: 0.5896\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 1s 501ms/step - loss: 0.5289 - val_loss: 0.5876\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 498ms/step - loss: 0.5286 - val_loss: 0.5871\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.5282 - val_loss: 0.5877\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 519ms/step - loss: 0.5277 - val_loss: 0.5881\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 880ms/step - loss: 0.5275 - val_loss: 0.5875\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 2s 809ms/step - loss: 0.5271 - val_loss: 0.5869\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 548ms/step - loss: 0.5269 - val_loss: 0.5859\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.5267 - val_loss: 0.5883\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.5265 - val_loss: 0.5858\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 530ms/step - loss: 0.5263 - val_loss: 0.5867\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.5262 - val_loss: 0.5874\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.5260 - val_loss: 0.5868\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 585ms/step - loss: 0.5258 - val_loss: 0.5859\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 872ms/step - loss: 0.5257 - val_loss: 0.5868\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 3s 870ms/step - loss: 0.5256 - val_loss: 0.5858\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.5256 - val_loss: 0.5872\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.5255 - val_loss: 0.5859\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 515ms/step - loss: 0.5255 - val_loss: 0.5872\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 0.5255 - val_loss: 0.5860\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 497ms/step - loss: 0.5253 - val_loss: 0.5863\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 1s 510ms/step - loss: 0.5252 - val_loss: 0.5873\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.5252 - val_loss: 0.5869\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 3s 923ms/step - loss: 0.5252 - val_loss: 0.5856\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 3s 950ms/step - loss: 0.5251 - val_loss: 0.5871\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 3s 997ms/step - loss: 0.5251 - val_loss: 0.5859\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 747ms/step - loss: 0.5250 - val_loss: 0.5860\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.5249 - val_loss: 0.5868\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 1s 515ms/step - loss: 0.5248 - val_loss: 0.5855\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.5249 - val_loss: 0.5868\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.5248 - val_loss: 0.5859\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 550ms/step - loss: 0.5247 - val_loss: 0.5866\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 2s 822ms/step - loss: 0.5247 - val_loss: 0.5869\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 2s 833ms/step - loss: 0.5246 - val_loss: 0.5856\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.5245 - val_loss: 0.5872\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 510ms/step - loss: 0.5245 - val_loss: 0.5853\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.5245 - val_loss: 0.5872\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.5245 - val_loss: 0.5863\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.5245 - val_loss: 0.5863\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 500ms/step - loss: 0.5245 - val_loss: 0.5870\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 585ms/step - loss: 0.5245 - val_loss: 0.5867\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 834ms/step - loss: 0.5245 - val_loss: 0.5874\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 810ms/step - loss: 0.5245 - val_loss: 0.5863\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5245 - val_loss: 0.5877\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 1s 492ms/step - loss: 0.5245 - val_loss: 0.5855\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 1s 491ms/step - loss: 0.5244 - val_loss: 0.5880\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 500ms/step - loss: 0.5245 - val_loss: 0.5861\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 2s 520ms/step - loss: 0.5246 - val_loss: 0.5892\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 529ms/step - loss: 0.5246 - val_loss: 0.5859\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 739ms/step - loss: 0.5246 - val_loss: 0.5878\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 803ms/step - loss: 0.5246 - val_loss: 0.5863\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 819ms/step - loss: 0.5246 - val_loss: 0.5877\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.5245 - val_loss: 0.5869\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 2s 559ms/step - loss: 0.5245 - val_loss: 0.5874\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 0.5244 - val_loss: 0.5863\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 1s 508ms/step - loss: 0.5245 - val_loss: 0.5876\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 535ms/step - loss: 0.5245 - val_loss: 0.5865\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 515ms/step - loss: 0.5246 - val_loss: 0.5879\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 716ms/step - loss: 0.5246 - val_loss: 0.5860\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 815ms/step - loss: 0.5248 - val_loss: 0.5883\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 853ms/step - loss: 0.5249 - val_loss: 0.5868\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.5248 - val_loss: 0.5865\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.5249 - val_loss: 0.5885\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.5248 - val_loss: 0.5853\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 1s 504ms/step - loss: 0.5248 - val_loss: 0.5878\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 495ms/step - loss: 0.5248 - val_loss: 0.5860\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 534ms/step - loss: 0.5247 - val_loss: 0.5872\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 704ms/step - loss: 0.5248 - val_loss: 0.5863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c8da877fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = SAE.predict(X_scl)\n",
        "print(X_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kJrZvuSTTdb",
        "outputId": "0ace0bfe-844e-4715-807f-546936f3b334"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 28ms/step\n",
            "(102, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=2, random_state=1, shuffle=True)\n",
        "rf_model = RandomForestClassifier(n_estimators=500, random_state=0)\n",
        "LR = LogisticRegression(random_state=0)\n",
        "lda_clf = LinearDiscriminantAnalysis()\n",
        "qda_clf = QuadraticDiscriminantAnalysis()\n",
        "gpc = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
        "svm_model = svm.SVC(random_state=1,kernel='rbf', probability=True)\n",
        "gnb = GaussianNB()\n",
        "dt_model = DecisionTreeClassifier(random_state=0)\n",
        "adb = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "modls=[rf_model,LR,lda_clf,qda_clf,gpc,svm_model,gnb,dt_model,adb]\n",
        "names=[\"RF\", \"LR\", \"LDA\", \"QDA\", \"GPC\", \"SVM\", \"NB\", \"DT\", \"AB\"]"
      ],
      "metadata": {
        "id": "HqZBIjUSU3nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X,Y=load_dataset(df)\n",
        "X=X_new\n",
        "size=X.shape[1]\n",
        "print(X.shape)\n",
        "#ws=create_ws(WB,'sae')\n",
        "#ws.write(0,0,  (size) )\n",
        "print('    Accuracy: recall: precision : F1 score: kappa: AUC  ' )\n",
        "for mo in range(9):\n",
        "    print(names[mo])\n",
        "    row=mo\n",
        "    col=1\n",
        "    scores = cross_val_score(modls[mo], X, Y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "    p_scores = cross_val_score(modls[mo], X, Y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
        "    r_scores = cross_val_score(modls[mo], X, Y, scoring='recall_macro', cv=cv, n_jobs=-1)\n",
        "    f_scores = cross_val_score(modls[mo], X, Y, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
        "    acc=(mean(scores)*100)\n",
        "    re= (mean(r_scores)*100)\n",
        "    pre=(mean(p_scores)*100)\n",
        "    f1=(mean(f_scores)*100)\n",
        "    print('    %.2f   %.2f   %.2f   %.2f' %(acc, re, pre, f1))\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "7nP3Hfq0VL_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the hightest weighted genes\n",
        "weight = SAE.get_weights()\n",
        "we_ts1=np.asarray(weight[0])\n",
        "we_ts2=np.asarray(weight[2])\n",
        "we_ts3=np.asarray(weight[4])\n",
        "aa=np.dot(we_ts1,we_ts2)\n",
        "result=np.dot(aa,we_ts3)\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk8vqKZkTdnN",
        "outputId": "42071928-fcaf-497e-cab2-18310c733a33"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12582, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_gene=result.shape[0]\n",
        "total_node=result.shape[1]\n",
        "gene_weight_list=[]\n",
        "for t_g in range(total_gene):\n",
        "    weight_sum=0\n",
        "\n",
        "    for node in range(total_node):\n",
        "        weight_sum=weight_sum+result[t_g][node]\n",
        "\n",
        "    #print(t_g)\n",
        "    #print(weight_sum)\n",
        "    gene_weight_list.append((t_g,weight_sum))\n",
        "print(t_g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9IlVBhT3tL",
        "outputId": "cf2f1047-2877-4c18-db7e-69693bb46d41"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gene_list=sorted(gene_weight_list,key=lambda gene_weight_list: gene_weight_list[1] ,reverse=True)\n",
        "top_gene=gene_list[:50]\n",
        "gen_data = [lis[0] for lis in top_gene]\n",
        "gene_data=np.asarray(gen_data)\n",
        "col_name=[]\n",
        "for col in NEW_dataset.columns:\n",
        "    col_name.append(col)\n",
        "gene_name=[]\n",
        "for ge_name in gene_data:\n",
        "    gene_name.append(col_name[ge_name])"
      ],
      "metadata": {
        "id": "WwAcntTsT-R1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hightest weighted genes\n",
        "gene_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOrGlVv_Uqq5",
        "outputId": "6dc6bb90-e26f-402f-9359-9cc824e37a19"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['38355_at',\n",
              " '39296_at',\n",
              " '34526_s_at',\n",
              " '315_at',\n",
              " '38319_at',\n",
              " '37078_at',\n",
              " '32438_at',\n",
              " '40396_at',\n",
              " '33238_at',\n",
              " '32649_at',\n",
              " '1633_g_at',\n",
              " '41273_at',\n",
              " '1021_at',\n",
              " '34831_at',\n",
              " '35832_at',\n",
              " '36630_at',\n",
              " '41164_at',\n",
              " '39771_at',\n",
              " '33405_at',\n",
              " '40203_at',\n",
              " '34224_at',\n",
              " '1961_f_at',\n",
              " '31593_at',\n",
              " '854_at',\n",
              " '33267_at',\n",
              " '316_g_at',\n",
              " '39643_at',\n",
              " 'AFFX-M27830_5_at',\n",
              " '40324_r_at',\n",
              " '39042_at',\n",
              " '33291_at',\n",
              " '347_s_at',\n",
              " '33130_at',\n",
              " '1972_s_at',\n",
              " '41544_at',\n",
              " '35936_g_at',\n",
              " '1106_s_at',\n",
              " '586_s_at',\n",
              " '31754_at',\n",
              " '33518_f_at',\n",
              " '39829_at',\n",
              " '35862_at',\n",
              " '31885_at',\n",
              " '40531_at',\n",
              " '34037_at',\n",
              " '31957_r_at',\n",
              " '33616_at',\n",
              " '41042_r_at',\n",
              " '31382_f_at',\n",
              " '31665_s_at']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}